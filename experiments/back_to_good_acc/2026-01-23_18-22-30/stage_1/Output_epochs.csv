Epoch,Training Loss,Validation Loss
1,0.13318532157056737,0.03862143040097901
2,0.028275207209855335,0.008216763187916816
3,0.008914134594811766,0.002018467129692777
4,0.003371130262948796,0.0009329449418005619
5,0.0015787111748301879,0.0004959314423003908
6,0.0008920815537910085,0.00022028523351230836
7,0.0005074009812535663,0.00014771267445058545
8,0.0004648506339968131,9.353111609256999e-05
9,0.0003267663041284459,6.596449655784761e-05
10,0.00018561439313908586,5.8559591081219844e-05
11,0.0002526143723090111,5.489542384375658e-05
12,0.00017604937782158455,7.506906440965787e-05
13,0.0001233031022859291,9.365541026419399e-05
14,0.00020600574247735343,5.493033361470747e-05
15,0.00012126708734420284,1.757603462133773e-05
16,6.368988730752717e-05,3.106352773604099e-05
17,0.0001347508206470121,1.353474539073413e-05
18,8.223051655328443e-05,4.3992852363154994e-05
19,5.4286569259457235e-05,5.010539439562421e-05
20,3.84787539957463e-05,7.716239926984342e-05
