Epoch,Training Loss,Validation Loss
1,0.2822009870162246,0.10708726415991054
2,0.08572293137908286,0.05338365430592762
3,0.0466259933546497,0.0245310956035606
4,0.024055005308128572,0.011679457827772785
5,0.012680115848105288,0.005494155249105057
6,0.006807206282515624,0.002742887953061102
7,0.003952659461312452,0.0015404961354529784
8,0.0023968590623881974,0.0008366954973576374
9,0.0015259536706511462,0.0005841981061229714
10,0.001021199212775246,0.0003951572239434047
11,0.0006837530491941536,0.0002622232679822985
12,0.000504109591347997,0.0001808954448297633
13,0.00042185937592304753,0.00017537506684116058
14,0.00030372751749254583,0.00012423489893923653
15,0.0002477923806454625,9.932912097316303e-05
16,0.0002221340071258114,0.00010324350257758373
17,0.00015969240201522812,0.00012465329650611557
18,0.00013438973982467814,0.00010641152725273805
19,0.00016198453848287136,8.66212806163359e-05
20,0.00011617307677497379,7.587945234159586e-05
21,9.827653870094371e-05,0.00019233068064333339
22,0.00010655382227859834,8.057466119126765e-05
23,9.178865776582256e-05,0.00012272473841054945
24,7.360022199589543e-05,6.374453801396535e-05
25,7.03885857924983e-05,0.00011677688835315743
26,4.3065509690111286e-05,7.923335837044659e-05
