Epoch,Training Loss,Validation Loss
1,0.6625755240277547,0.6198158936685069
2,0.5552555766047501,0.48264186409000465
3,0.4344458793236957,0.3736415209813905
4,0.3424102765757863,0.298468829779421
5,0.275443374504888,0.245030399070495
6,0.22940599143020507,0.2056900904401985
7,0.19647656926294652,0.1789894053625235
8,0.17217884376281645,0.1583545854098928
9,0.1542575822128513,0.14404791481261825
10,0.1397005248118222,0.1306883829461824
11,0.12829494415744533,0.11845367967839639
12,0.11860829646267541,0.11035486797815428
13,0.11016269228080423,0.10294446426532905
14,0.10267449394474185,0.09590847357773732
15,0.09652220494136578,0.08949247219594093
16,0.09091978889655292,0.08414003970727416
17,0.08544471211792008,0.07844927823531408
18,0.0800654298164011,0.07419489395412068
19,0.07519286919415481,0.06933222104873045
20,0.07055111907846559,0.06427585328274735
21,0.06609019397841237,0.060636157644134915
22,0.0619388922019218,0.05662513067547512
23,0.05776618781491993,0.05211276696831777
24,0.05401500408363536,0.04890607489375379
25,0.050727816768051166,0.04550243958132816
26,0.04717590523565688,0.04216379739055808
27,0.043909270376936205,0.03890985854789463
28,0.04093328990587374,0.03648360875528116
29,0.03818650993450386,0.03379772610719602
30,0.03571287946911847,0.031866515351197625
31,0.03347371114281619,0.02950024257305926
32,0.031420855215046464,0.027158459269132487
33,0.02921845352019721,0.02538913488767419
34,0.027254724451075723,0.023775931053212608
35,0.02554306194065063,0.022261661593090978
36,0.024101730935820718,0.020797995328827326
37,0.022401089878465102,0.019189722858779058
38,0.021088989724109813,0.01767283914015152
39,0.01949640557291062,0.017028144056208873
40,0.018329679133082793,0.015688915551088128
