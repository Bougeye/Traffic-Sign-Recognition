Fold,Epoch,Training Loss,Validation Loss
1,1,0.18764749296818808,0.06055512356661002
1,2,0.04294330654746564,0.017379020570251945
1,3,0.015183307280576864,0.005510771576440352
1,4,0.005790635682205531,0.0019125429365230069
1,5,0.0025186825634233466,0.0008435014639118053
1,6,0.0012368467364780565,0.0004480432441824186
1,7,0.0007144030967056713,0.00030675326194116266
1,8,0.0004172440229129739,0.00022749525384978408
1,9,0.00033219008976948617,0.00022518058039429134
1,10,0.0002273697991777407,0.00027344830402737633
1,11,0.000188222846221521,0.00023734212039233435
1,12,0.00013806518663094712,0.00025231493559834675
1,13,0.00014019220522503516,0.00012210791495458477
1,14,0.00010835025666573672,0.00010675253606548207
1,15,0.00012119707060117287,0.00012045035474976243
1,16,9.198494108329837e-05,0.0001631315923344372
1,17,9.946274719587748e-05,9.850978602972589e-05
1,18,5.561584777704398e-05,0.00016170803300120771
1,19,4.445592486035473e-05,0.00015151789516716597
