epochs: 5
lr: 0.001
bsize: 64               #batchsize
optimizer: "adam"
folds: 5
earliest_stop: 0.04      #ratio of training process at which early stopping is enabled
bpdc: 1                #batches per data collection to collect metrics throughout an epoch
