Downloading: "https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth" to /vol/fob-vol1/mi23/ziglowsa/venvs/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth
0.2%0.3%0.5%0.6%0.8%0.9%1.1%1.2%1.4%1.5%1.7%1.8%2.0%2.1%2.3%2.4%2.6%2.7%2.9%3.0%3.2%3.3%3.5%3.6%3.8%3.9%4.1%4.2%4.4%4.5%4.7%4.8%5.0%5.1%5.3%5.4%5.6%5.7%5.9%6.0%6.2%6.3%6.5%6.7%6.8%7.0%7.1%7.3%7.4%7.6%7.7%7.9%8.0%8.2%8.3%8.5%8.6%8.8%8.9%9.1%9.2%9.4%9.5%9.7%9.8%10.0%10.1%10.3%10.4%10.6%10.7%10.9%11.0%11.2%11.3%11.5%11.6%11.8%11.9%12.1%12.2%12.4%12.5%12.7%12.8%13.0%13.1%13.3%13.5%13.6%13.8%13.9%14.1%14.2%14.4%14.5%14.7%14.8%15.0%15.1%15.3%15.4%15.6%15.7%15.9%16.0%16.2%16.3%16.5%16.6%16.8%16.9%17.1%17.2%17.4%17.5%17.7%17.8%18.0%18.1%18.3%18.4%18.6%18.7%18.9%19.0%19.2%19.3%19.5%19.6%19.8%20.0%20.1%20.3%20.4%20.6%20.7%20.9%21.0%21.2%21.3%21.5%21.6%21.8%21.9%22.1%22.2%22.4%22.5%22.7%22.8%23.0%23.1%23.3%23.4%23.6%23.7%23.9%24.0%24.2%24.3%24.5%24.6%24.8%24.9%25.1%25.2%25.4%25.5%25.7%25.8%26.0%26.1%26.3%26.4%26.6%26.8%26.9%27.1%27.2%27.4%27.5%27.7%27.8%28.0%28.1%28.3%28.4%28.6%28.7%28.9%29.0%29.2%29.3%29.5%29.6%29.8%29.9%30.1%30.2%30.4%30.5%30.7%30.8%31.0%31.1%31.3%31.4%31.6%31.7%31.9%32.0%32.2%32.3%32.5%32.6%32.8%32.9%33.1%33.3%33.4%33.6%33.7%33.9%34.0%34.2%34.3%34.5%34.6%34.8%34.9%35.1%35.2%35.4%35.5%35.7%35.8%36.0%36.1%36.3%36.4%36.6%36.7%36.9%37.0%37.2%37.3%37.5%37.6%37.8%37.9%38.1%38.2%38.4%38.5%38.7%38.8%39.0%39.1%39.3%39.4%39.6%39.8%39.9%40.1%40.2%40.4%40.5%40.7%40.8%41.0%41.1%41.3%41.4%41.6%41.7%41.9%42.0%42.2%42.3%42.5%42.6%42.8%42.9%43.1%43.2%43.4%43.5%43.7%43.8%44.0%44.1%44.3%44.4%44.6%44.7%44.9%45.0%45.2%45.3%45.5%45.6%45.8%45.9%46.1%46.2%46.4%46.6%46.7%46.9%47.0%47.2%47.3%47.5%47.6%47.8%47.9%48.1%48.2%48.4%48.5%48.7%48.8%49.0%49.1%49.3%49.4%49.6%49.7%49.9%50.0%50.2%50.3%50.5%50.6%50.8%50.9%51.1%51.2%51.4%51.5%51.7%51.8%52.0%52.1%52.3%52.4%52.6%52.7%52.9%53.1%53.2%53.4%53.5%53.7%53.8%54.0%54.1%54.3%54.4%54.6%54.7%54.9%55.0%55.2%55.3%55.5%55.6%55.8%55.9%56.1%56.2%56.4%56.5%56.7%56.8%57.0%57.1%57.3%57.4%57.6%57.7%57.9%58.0%58.2%58.3%58.5%58.6%58.8%58.9%59.1%59.2%59.4%59.5%59.7%59.9%60.0%60.2%60.3%60.5%60.6%60.8%60.9%61.1%61.2%61.4%61.5%61.7%61.8%62.0%62.1%62.3%62.4%62.6%62.7%62.9%63.0%63.2%63.3%63.5%63.6%63.8%63.9%64.1%64.2%64.4%64.5%64.7%64.8%65.0%65.1%65.3%65.4%65.6%65.7%65.9%66.0%66.2%66.4%66.5%66.7%66.8%67.0%67.1%67.3%67.4%67.6%67.7%67.9%68.0%68.2%68.3%68.5%68.6%68.8%68.9%69.1%69.2%69.4%69.5%69.7%69.8%70.0%70.1%70.3%70.4%70.6%70.7%70.9%71.0%71.2%71.3%71.5%71.6%71.8%71.9%72.1%72.2%72.4%72.5%72.7%72.9%73.0%73.2%73.3%73.5%73.6%73.8%73.9%74.1%74.2%74.4%74.5%74.7%74.8%75.0%75.1%75.3%75.4%75.6%75.7%75.9%76.0%76.2%76.3%76.5%76.6%76.8%76.9%77.1%77.2%77.4%77.5%77.7%77.8%78.0%78.1%78.3%78.4%78.6%78.7%78.9%79.0%79.2%79.3%79.5%79.7%79.8%80.0%80.1%80.3%80.4%80.6%80.7%80.9%81.0%81.2%81.3%81.5%81.6%81.8%81.9%82.1%82.2%82.4%82.5%82.7%82.8%83.0%83.1%83.3%83.4%83.6%83.7%83.9%84.0%84.2%84.3%84.5%84.6%84.8%84.9%85.1%85.2%85.4%85.5%85.7%85.8%86.0%86.2%86.3%86.5%86.6%86.8%86.9%87.1%87.2%87.4%87.5%87.7%87.8%88.0%88.1%88.3%88.4%88.6%88.7%88.9%89.0%89.2%89.3%89.5%89.6%89.8%89.9%90.1%90.2%90.4%90.5%90.7%90.8%91.0%91.1%91.3%91.4%91.6%91.7%91.9%92.0%92.2%92.3%92.5%92.6%92.8%93.0%93.1%93.3%93.4%93.6%93.7%93.9%94.0%94.2%94.3%94.5%94.6%94.8%94.9%95.1%95.2%95.4%95.5%95.7%95.8%96.0%96.1%96.3%96.4%96.6%96.7%96.9%97.0%97.2%97.3%97.5%97.6%97.8%97.9%98.1%98.2%98.4%98.5%98.7%98.8%99.0%99.1%99.3%99.5%99.6%99.8%99.9%100.0%
/vol/fob-vol1/mi23/ziglowsa/Payload/src/training/training_loop.py:66: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == "cuda"))
